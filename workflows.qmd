---
format: revealjs
---

## Workflows for reproducible, replicable, scalable science

Mark Adams, The University of Edinburgh\
Tech Talk, 13 Aug 2024

âœ‰ï¸ `mark.adams@ed.uk`  
ðŸ˜`@markjamesadams@genomic.social`  
ðŸ¦‹`@markjamesadams.bsky.social`  
ð•`@mja`

---

## The "-ables" of workflows

::: {.incremental}

- **reproducible**: same data and same code produce the same results
- **replicable**: same code runs with different data
- **scalable**: some code runs with more data and more resources

:::

---

## A workflow is a graph

```{mermaid}
flowchart LR
  D[Data] --> T[[Computation]]
  C{{Code}} --> T
  T --> R{Results}
```

---

## A workflow is a graph

```{mermaid}
flowchart LR
  D[Data] --> T[[Computation 1]]
  C{{Code 1}} --> T
  T --> T2[[Computation 2]] --> R{Results}
  C2{{Code 2}} --> T2
```

---

## A workflow is a graph

```{mermaid}
flowchart LR
  D[Data] --> T[[Computation 1]]
  C{{Code 1}} --> T
  T --> T2[[Computation 2]] --> R{Results}
  C2{{Code 2*}} --> T2
  style C2 stroke:#f66,stroke-width:2px,stroke-dasharray: 5 5
  style T2 stroke:#f66,stroke-width:2px,stroke-dasharray: 5 5
  style R stroke:#f66,stroke-width:2px,stroke-dasharray: 5 5
```

When inputs change, only re-compute descendent outputs.

---

## A workflow is a build system

Collection of notebooks.
```{.sh code-line-numbers="false"}
document.qmd    presentation.qmd    workflows.qmd
```
  
Render them in a loop.
```{.sh code-line-numbers="false"}
$ for QMD in *.qmd; do
    quarto render $QMD
  done
```

---

## Keep it DRY

Only render the notebook if the HTML doesn't exist or the notebook is newer.

```{.sh code-line-numbers="false"}
$ for QMD in *.qmd; do
    PREFIX=$(basename $QMD .qmd)
    if [ ! -e ${PREFIX}.html ] || [ ${PREFIX}.qmd -nt ${PREFIX}.html ]; then
      quarto render $QMD
    fi
  done
```

---

## Makefiles[^1]

GNU Make: a tool for building programs from source code.

```makefile
output : inputs
  command
```

Rules encode relationship between inputs ("depenencies") and outputs ("targets")

[^1]: https://book.the-turing-way.org/reproducible-research/make

---

`Makefile` with one rule:
```{.makefile filename="Makefile"}
workflows.html : workflows.qmd
	quarto render workflows.qmd
```

Run `make`
```{.sh code-line-numbers="false"}
$ make workflows.html

quarto render workflows.qmd

processing file: workflows.qmd
1/3
2/3 [unnamed-chunk-1]
3/3
output file: workflows.knit.md
...
Output created: workflows.html
```

```{.sh code-line-numbers="false"}
$ make workflows.html

make: `workflows.html' is up to date.
```
---

## Makefile pattern rules

Pattern rule to render an HTML file from any Quarto notebook.

```{.makefile filename="Makefile"}
%.html : %.qmd
	quarto render $<

all: workflows.html symposium.html thesis.html
```

`all` rule specifies the specific outputs to render.

---

## Workflows are pipelines

```{mermaid}
flowchart LR
  S1[[Step 1]] --> S2[[Step 2]] --> S3[[Step 3]]
```

Unix pipes
```{.sh code-line-numbers="false"}
bcftools view --targets-file targets.tsv dbsnp.v153.b37.vcf.gz |\
bcftools query --print-header --format '%CHROM\t%POS\t%ID\t%REF\t%ALT{0}\n' |\
gzip -c > chr_pos_rsid.tsv.gz
```

Scheduler (Sun Grid Engine) dependencies
```{.sh filename="step1.sh"}
#$ -cwd
command1 --in $1 --out $2
```
```{.sh filename="step2.sh"}
#$ -cwd
command2 --in $1 --out $2
```

```{.sh code-line-numbers="false"}
$ qsub -N step1 step1.sh input1 output1
$ qsub -N step2 -hold_jid step1 step2.sh output1 output2
```

---


## Workflows are parallelisable 

```{mermaid}
flowchart LR
  S1[[Split]] --> S2[[Compute]] --> S3[[Combine]]
  S1 --> S22[[Compute]] --> S3[[Combine]]
  S1 --> S23[[Compute]] --> S3[[Combine]]
  S1 --> S24[[Compute]] --> S3[[Combine]]
  S1 --> S25[[Compute]] --> S3[[Combine]]
```

```{.sh code-line-numbers="false"}
$ make all -j 3

quarto render workflows.qmd
quarto render symposium.qmd
quarto render thesis.qmd
```

---

## Limitations of Makefiles

- No understanding of problem domain (need to run scripts, not just shell commands)
- Not scalable (only executes on local machine, not via schedulers)
- Limited parallelisation

## Limitations of schedulers

- Manually manage connecting outputs to next inputs
- Not portable

---

# Examples

---

## Multi-ancestry genetic association study (UK Biobank, AllofUs, etc)

```{mermaid}
flowchart LR
  ANC[(Ancestry clusters)]
  ANC --> AFR[Cluster 1] --> KEEP_AFR[[Genotype QC]] --> STEP1_AFR[[Genome regression]] --> STEP2_AFR[[Genome association]]
  ANC --> EAS[Cluster 2] --> KEEP_EAS[[Genotype QC]] --> STEP1_EAS[[Genome regression]] --> STEP2_EAS[[Genome association]]
  ANC --> EUR[Cluster 3] --> KEEP_EUR[[Genotype QC]] --> STEP1_EUR[[Genome regression]] --> STEP2_EUR[[Genome association]]

  
  BFILE[(Genotype array)]
  BFILE --> KEEP_AFR
  BFILE --> KEEP_EAS
  BFILE --> KEEP_EUR
  
  P[(Phenotypes and covariates)]
  P --> STEP1_AFR
  P --> STEP1_EAS
  P --> STEP1_EUR
  
  
  PFILE[(Imputed genotypes)]
  
  P --> STEP2_AFR
  PFILE --> STEP2_AFR
  STEP2_AFR -. 1-22,X .-> STEP2_AFR
  
  P --> STEP2_EAS
  PFILE --> STEP2_EAS
  STEP2_EAS -. 1-22,X .-> STEP2_EAS
  
  P --> STEP2_EUR
  PFILE --> STEP2_EUR
  STEP2_EUR -. 1-22,X .-> STEP2_EUR
  
  META[[Meta-analysis]]
  STEP2_AFR --> META
  STEP2_EAS --> META
  STEP2_EUR --> META
```

---

## Inputs

```{.groovy filename="ukb-regenie-hrc.nf"}
params.bt = null // binary phenotypes file
params.qt = null // quantitative phenotypes file 
params.keep = "rf_hgdp1kg_clusters.keep"
params.remove = "PGC.remove"
params.bfile = "autosome.{bed,bim,fam}"
params.pfile = "ukb_imp_v3.qc.{pgen,psam,pvar}"
params.clusters = "ukb_randomforest_clusters.tsv"
params.covar = "ukb_randomforest_clusters.covar"
params.covar_list = "PC1,PC2,PC3,PC4,PC5,PC6"
params.covar_cat_list = "sex,genotyping"
params.min_cases = 80
```

---

### Parse inputs from CSV/TSV file

```groovy
// genetic similarity clusters
	CLUSTERS_CH = Channel
		.fromPath(params.clusters, checkIfExists: true)
		
// parse cluster file to get names of each cluster
CLUSTER_NAMES_CH = CLUSTERS_CH
		.splitCsv(sep: "\t", skip: 1, header: ['fid', 'iid', 'cluster'])
		.map { it -> it.cluster }
		.unique()
```

- `splitCsv()`: parse delimited file. Each row becomes an item.
- `map()`: get value of `cluster` column for each item.
- `unique()` output unique items.

---